{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Support Vector Machines\n",
    "## Classification Using SVM\n",
    "Load dataset. We will use w1a dataset from LibSVM datasets https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original optimization problem for the Support Vector Machine (SVM) is given by\n",
    "\\begin{equation}\\label{eq:primal}\n",
    "  \\min_{w \\in R^d} \\  \\sum_{i=1}^n \\ell(y_i A_i^\\top w) + \\frac\\lambda2 \\|w\\|^2\n",
    "\\end{equation}\n",
    "where $\\ell : R\\rightarrow R$, $\\ell(z) := \\max\\{0,1-z\\}$ is the hinge loss function.\n",
    "Here for any $i$, $1\\le i\\le n$, the vector $A_i\\in R^d$ is the $i$-th data example, and $y_i\\in\\{\\pm1\\}$ is the corresponding label.\n",
    "  \n",
    "The dual optimization problem for the SVM is given by \n",
    "\\begin{equation}\\label{eq:dual}\n",
    " \\max_{\\boldsymbol{\\alpha} \\in R^n } \\  \\alpha^\\top\\boldsymbol{1} - \\tfrac1{2\\lambda} \\alpha^\\top Y A A^\\top Y\\alpha\n",
    " \\text{    such that    $0\\le \\alpha_i \\le 1  \\ \\forall i$}\n",
    "\\end{equation}\n",
    "where $Y := \\mathop{diag}(y)$, and $A\\in R^{n \\times d}$ again collects all $n$ data examples as its columns. \n",
    "\n",
    "Note that $w$ can be derived from $\\alpha$ as\n",
    "\\begin{equation}\n",
    "    w(\\alpha) = \\frac{1}{\\lambda} A^\\top Y \\alpha.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2477,) (2477, 300)\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = 'data/w1a'\n",
    "\n",
    "A, y = load_svmlight_file(DATA_TRAIN_PATH)\n",
    "A = A.toarray()\n",
    "print(y.shape, A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare cost and prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_primal_objective(y, A, w, lambda_):\n",
    "    \"\"\"\n",
    "    Compute the full cost (the primal objective), that is loss plus regularizer.\n",
    "    y: +1 or -1 labels, shape = (num_examples)\n",
    "    A: Dataset matrix, shape = (num_examples, num_features)\n",
    "    w: Model weights, shape = (num_features)\n",
    "    return: scalar value\n",
    "    \"\"\"\n",
    "    regularizer = lambda_ * np.linalg.norm(w, 2)**2\n",
    "    loss = np.sum(np.maximum(1 - y * (A @ w), 0))\n",
    "    return loss + regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y, A, w):\n",
    "    \"\"\"\n",
    "    Compute the training accuracy on the training set (can be called for test set as well).\n",
    "    y: +1 or -1 labels, shape = (num_examples)\n",
    "    A: Dataset matrix, shape = (num_examples, num_features)\n",
    "    w: Model weights, shape = (num_features)\n",
    "    return: scalar value\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    pred = np.sign(A @ w)\n",
    "    pred[np.where(pred==0)[0]] = 1\n",
    "    acc = np.sum(pred == y) / len(pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Descent (Ascent) for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the closed-form update for the i-th variable alpha, in the dual optimization problem, given alpha and the current corresponding w.\n",
    "\n",
    "\n",
    "Hints: \n",
    "- Differentiate the dual objective with respect to one `alpha[i]`.\n",
    "- Set the derivative to zero to compute a new `alpha[i]`.\n",
    "- Make sure the values of alpha stay inside a `[0, 1]` box.\n",
    "- You can formulate the update as `alpha[i] = projection(alpha[i] + lambda_ * (some update))`.\n",
    "- You can test the correctness of your implementation by checking if the difference between the dual objective and primal objective goes to zero. This difference, the duality gap, should get smaller than 10 in 700000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coordinate_update(y, A, lambda_, alpha, w, i):\n",
    "    \"\"\"\n",
    "    Compute a coordinate update (closed form) for coordinate i.\n",
    "    y: +1 or -1 labels, shape = (num_examples)\n",
    "    A: Dataset matrix, shape = (num_examples, num_features)\n",
    "    lambda_: Regularization parameter, scalar\n",
    "    alpha: Dual variables, shape = (num_examples)\n",
    "    w: Model weights, shape = (num_examples)\n",
    "    i: Index of the entry of the dual variable 'alpha' that is to be updated\n",
    "    return: New weights w (shape (num_features)), New dual variables alpha (shape (num_examples))\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    # calculate the update of coordinate at index=n.\n",
    "    a_i, y_i = A[i], y[i]\n",
    "    old_alpha_i = np.copy(alpha[i])\n",
    "    \n",
    "    idxs = np.append(np.arange(i), np.arange(i+1, len(y)))\n",
    "    \n",
    "    alpha[i] = (lambda_ - np.sum(((A[idxs].T * (y_i * y[idxs] * alpha[idxs]))).T @ a_i)) / np.linalg.norm(a_i)**2\n",
    "    alpha[i] = np.maximum(np.minimum(alpha[i], 1), 0)\n",
    "    \n",
    "    w = w + a_i * ((y_i * (alpha[i] - old_alpha_i)) / lambda_)\n",
    "    \n",
    "    return w, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dual_objective(y, A, w, alpha, lambda_):\n",
    "    \"\"\"\n",
    "    Calculate the objective for the dual problem.\n",
    "    Follow the formula given above.\n",
    "    y: +1 or -1 labels, shape = (num_examples)\n",
    "    A: Dataset matrix, shape = (num_examples, num_features)\n",
    "    alpha: Dual variables, shape = (num_examples)\n",
    "    lambda_: Regularization parameter, scalar\n",
    "    return: Scalar value\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    \n",
    "    return np.sum(alpha) - (1 / (2*lambda_)) * np.sum((alpha * y) @ A @ A.T @ (y * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16805/429604365.py:22: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  alpha[i] = (lambda_ - np.sum(((A[idxs].T * (y_i * y[idxs] * alpha[idxs]))).T @ a_i)) / np.linalg.norm(a_i)**2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=0, primal:2477.00000, dual:1.00000, gap:2476.00000\n",
      "iteration=1000, primal:423.93571, dual:78.27808, gap:345.65762\n",
      "iteration=2000, primal:544.27900, dual:117.46075, gap:426.81825\n",
      "iteration=3000, primal:452.47932, dual:144.65356, gap:307.82575\n",
      "iteration=4000, primal:369.59819, dual:165.78682, gap:203.81137\n",
      "iteration=5000, primal:359.19594, dual:180.87137, gap:178.32457\n",
      "iteration=6000, primal:353.42006, dual:184.97332, gap:168.44674\n",
      "iteration=7000, primal:349.03114, dual:193.11221, gap:155.91893\n",
      "iteration=8000, primal:363.02717, dual:198.30214, gap:164.72503\n",
      "iteration=9000, primal:346.53978, dual:201.44288, gap:145.09690\n",
      "iteration=10000, primal:363.38976, dual:203.58812, gap:159.80164\n",
      "iteration=11000, primal:358.73336, dual:205.77176, gap:152.96160\n",
      "iteration=12000, primal:339.65175, dual:205.97470, gap:133.67705\n",
      "iteration=13000, primal:321.16338, dual:207.08042, gap:114.08296\n",
      "iteration=14000, primal:352.54205, dual:207.21749, gap:145.32456\n",
      "iteration=15000, primal:387.51731, dual:209.34792, gap:178.16939\n",
      "iteration=16000, primal:330.91081, dual:209.42668, gap:121.48413\n",
      "iteration=17000, primal:333.53455, dual:209.52173, gap:124.01281\n",
      "iteration=18000, primal:317.92503, dual:209.60742, gap:108.31761\n",
      "iteration=19000, primal:313.02967, dual:209.70002, gap:103.32965\n",
      "iteration=20000, primal:316.26148, dual:209.75151, gap:106.50996\n",
      "iteration=21000, primal:333.84243, dual:209.86370, gap:123.97873\n",
      "iteration=22000, primal:363.52765, dual:209.98338, gap:153.54427\n",
      "iteration=23000, primal:322.91538, dual:210.06620, gap:112.84918\n",
      "iteration=24000, primal:402.01624, dual:210.16135, gap:191.85488\n",
      "iteration=25000, primal:319.29340, dual:210.22286, gap:109.07054\n",
      "iteration=26000, primal:308.50798, dual:210.30083, gap:98.20715\n",
      "iteration=27000, primal:319.87739, dual:210.44706, gap:109.43033\n",
      "iteration=28000, primal:315.50987, dual:210.61752, gap:104.89235\n",
      "iteration=29000, primal:297.18331, dual:210.70622, gap:86.47709\n",
      "iteration=30000, primal:361.47969, dual:210.77721, gap:150.70249\n",
      "iteration=31000, primal:300.06478, dual:210.83408, gap:89.23070\n",
      "iteration=32000, primal:342.56861, dual:210.93914, gap:131.62946\n",
      "iteration=33000, primal:298.77445, dual:210.99611, gap:87.77834\n",
      "iteration=34000, primal:294.24335, dual:211.08022, gap:83.16313\n",
      "iteration=35000, primal:286.92059, dual:211.12653, gap:75.79407\n",
      "iteration=36000, primal:301.39151, dual:211.18115, gap:90.21036\n",
      "iteration=37000, primal:296.90031, dual:211.23109, gap:85.66923\n",
      "iteration=38000, primal:298.11466, dual:211.32091, gap:86.79375\n",
      "iteration=39000, primal:299.40975, dual:211.45768, gap:87.95207\n",
      "iteration=40000, primal:301.32452, dual:211.56551, gap:89.75901\n",
      "iteration=41000, primal:296.42148, dual:211.64309, gap:84.77839\n",
      "iteration=42000, primal:296.27510, dual:211.74187, gap:84.53324\n",
      "iteration=43000, primal:298.88517, dual:211.86129, gap:87.02389\n",
      "iteration=44000, primal:298.73059, dual:212.00426, gap:86.72633\n",
      "iteration=45000, primal:300.17922, dual:212.12923, gap:88.05000\n",
      "iteration=46000, primal:309.56364, dual:212.21063, gap:97.35301\n",
      "iteration=47000, primal:315.09862, dual:212.32691, gap:102.77172\n",
      "iteration=48000, primal:443.41643, dual:212.49377, gap:230.92266\n",
      "iteration=49000, primal:280.51464, dual:212.55458, gap:67.96006\n",
      "iteration=50000, primal:290.73269, dual:212.58583, gap:78.14686\n",
      "iteration=51000, primal:288.93193, dual:212.72309, gap:76.20883\n",
      "iteration=52000, primal:291.75192, dual:212.84986, gap:78.90206\n",
      "iteration=53000, primal:341.00456, dual:213.05506, gap:127.94950\n",
      "iteration=54000, primal:291.80884, dual:213.16181, gap:78.64703\n",
      "iteration=55000, primal:292.45419, dual:213.29079, gap:79.16340\n",
      "iteration=56000, primal:295.40485, dual:213.34813, gap:82.05672\n",
      "iteration=57000, primal:315.99119, dual:213.45422, gap:102.53697\n",
      "iteration=58000, primal:282.57408, dual:213.56340, gap:69.01068\n",
      "iteration=59000, primal:297.34117, dual:213.62526, gap:83.71591\n",
      "iteration=60000, primal:299.81506, dual:213.73037, gap:86.08469\n",
      "iteration=61000, primal:306.19110, dual:213.83457, gap:92.35654\n",
      "iteration=62000, primal:283.18003, dual:213.92813, gap:69.25190\n",
      "iteration=63000, primal:318.69822, dual:213.99891, gap:104.69930\n",
      "iteration=64000, primal:291.38716, dual:214.06623, gap:77.32092\n",
      "iteration=65000, primal:290.02555, dual:214.18944, gap:75.83611\n",
      "iteration=66000, primal:283.07926, dual:214.24923, gap:68.83003\n",
      "iteration=67000, primal:284.82659, dual:214.34484, gap:70.48175\n",
      "iteration=68000, primal:298.53410, dual:214.39366, gap:84.14045\n",
      "iteration=69000, primal:292.83614, dual:214.46776, gap:78.36838\n",
      "iteration=70000, primal:275.15352, dual:214.50099, gap:60.65253\n",
      "iteration=71000, primal:271.42295, dual:214.53001, gap:56.89295\n",
      "iteration=72000, primal:272.67587, dual:214.56552, gap:58.11035\n",
      "iteration=73000, primal:265.85395, dual:214.59741, gap:51.25654\n",
      "iteration=74000, primal:274.24222, dual:214.66341, gap:59.57880\n",
      "iteration=75000, primal:275.18563, dual:214.69391, gap:60.49172\n",
      "iteration=76000, primal:270.69590, dual:214.70575, gap:55.99015\n",
      "iteration=77000, primal:267.88937, dual:214.74474, gap:53.14463\n",
      "iteration=78000, primal:269.01136, dual:214.84238, gap:54.16898\n",
      "iteration=79000, primal:266.74733, dual:214.88075, gap:51.86658\n",
      "iteration=80000, primal:305.45672, dual:215.05172, gap:90.40500\n",
      "iteration=81000, primal:271.02605, dual:215.09667, gap:55.92938\n",
      "iteration=82000, primal:270.03065, dual:215.16444, gap:54.86622\n",
      "iteration=83000, primal:277.95923, dual:215.24076, gap:62.71847\n",
      "iteration=84000, primal:266.88627, dual:215.26974, gap:51.61653\n",
      "iteration=85000, primal:284.98153, dual:215.34422, gap:69.63731\n",
      "iteration=86000, primal:275.23272, dual:215.38177, gap:59.85094\n",
      "iteration=87000, primal:277.27926, dual:215.49288, gap:61.78638\n",
      "iteration=88000, primal:273.61917, dual:215.52744, gap:58.09173\n",
      "iteration=89000, primal:266.43644, dual:215.62409, gap:50.81236\n",
      "iteration=90000, primal:275.27689, dual:215.64945, gap:59.62744\n",
      "iteration=91000, primal:271.29961, dual:215.72510, gap:55.57450\n",
      "iteration=92000, primal:281.01370, dual:215.75710, gap:65.25660\n",
      "iteration=93000, primal:308.47953, dual:215.84670, gap:92.63283\n",
      "iteration=94000, primal:284.19478, dual:215.89669, gap:68.29808\n",
      "iteration=95000, primal:271.05003, dual:215.96199, gap:55.08804\n",
      "iteration=96000, primal:266.23133, dual:215.99324, gap:50.23809\n",
      "iteration=97000, primal:283.20189, dual:216.05151, gap:67.15037\n",
      "iteration=98000, primal:276.61820, dual:216.09143, gap:60.52676\n",
      "iteration=99000, primal:284.68480, dual:216.15566, gap:68.52914\n",
      "training accuracy = 0.8942268873637464\n",
      "defaultdict(<class 'list'>, {'objective_function': [2477.0, 423.93570550171, 544.279001989984, 452.479315944164, 369.59818920983014, 359.1959381916138, 353.4200554211486, 349.03114072736184, 363.02717413217357, 346.539781560028, 363.38976399841505, 358.73336207739663, 339.6517503306949, 321.16338307379493, 352.54204987418274, 387.5173093834252, 330.91081361359323, 333.53454687200684, 317.92502912278735, 313.02966704711287, 316.2614787905255, 333.8424289555596, 363.5276518670882, 322.9153841208819, 402.016237892521, 319.2934026061667, 308.5079801779123, 319.87739479456286, 315.50986877806065, 297.1833080018207, 361.47969371136554, 300.06477887905265, 342.56860636316645, 298.77444551151183, 294.24334793239615, 286.92059405229963, 301.3915052358094, 296.90031349308356, 298.114658815367, 299.40975061988036, 301.3245200391049, 296.42147709674015, 296.27510352363817, 298.88517271635175, 298.7305943907483, 300.1792241408704, 309.5636371862859, 315.098623375468, 443.41642827053295, 280.5146423662535, 290.7326891561604, 288.9319291700306, 291.75192259557457, 341.00455584809794, 291.8088417426342, 292.4541911402685, 295.4048508930263, 315.99118702258386, 282.574076982738, 297.3411704785743, 299.8150623274396, 306.19110256990905, 283.1800262709979, 318.69821627494844, 291.38715806170023, 290.0255493753237, 283.07926145124446, 284.82659230389777, 298.53410278100546, 292.83613666369155, 275.1535214139272, 271.42295380528606, 272.67586860872524, 265.8539482297906, 274.2422168237063, 275.1856268117774, 270.69590156512436, 267.8893683211083, 269.0113602213679, 266.7473252391846, 305.45671536622336, 271.0260530047562, 270.03065321707464, 277.959230522783, 266.88627240068394, 284.98153218269067, 275.23271569578486, 277.2792579406106, 273.61917073608976, 266.43644437735617, 275.27688923040347, 271.29960638797746, 281.0136994406214, 308.47952783414627, 284.1947764057175, 271.0500308225462, 266.23132546033605, 283.2018867123601, 276.618198705076, 284.6847959929897], 'iter': [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000]})\n"
     ]
    }
   ],
   "source": [
    "def coordinate_descent_for_svm_demo(y, A, trace=False):\n",
    "    max_iter = 100000\n",
    "    lambda_ = 0.01\n",
    "    history = defaultdict(list) if trace else None\n",
    "    \n",
    "    num_examples, num_features = A.shape\n",
    "    w = np.zeros(num_features)\n",
    "    alpha = np.zeros(num_examples)\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        # i = sample one data point uniformly at random from the columns of A\n",
    "        i = random.randint(0,num_examples-1)\n",
    "        \n",
    "        w, alpha = calculate_coordinate_update(y, A, lambda_, alpha, w, i)\n",
    "        \n",
    "        if it % 1000 == 0:\n",
    "            # primal objective\n",
    "            primal_value = calculate_primal_objective(y, A, w, lambda_)\n",
    "            # dual objective\n",
    "            dual_value = calculate_dual_objective(y, A, w, alpha, lambda_)\n",
    "            # primal dual gap\n",
    "            duality_gap = primal_value - dual_value\n",
    "\n",
    "            print('iteration=%i, primal:%.5f, dual:%.5f, gap:%.5f'%(\n",
    "                    it, primal_value, dual_value, duality_gap))\n",
    "        if it % 1000 == 0:\n",
    "            primal_value = calculate_primal_objective(y, A, w, lambda_)\n",
    "            if trace:\n",
    "                history[\"objective_function\"] += [primal_value]\n",
    "                history['iter'].append(it)\n",
    "\n",
    "            \n",
    "    print(\"training accuracy = {l}\".format(l=calculate_accuracy(y, A, w)))\n",
    "    return history\n",
    "\n",
    "history_cd = coordinate_descent_for_svm_demo(y, A, trace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare it with SGD on original problem for the SVM. In this part, you will implement stochastic gradient descent on the primal SVM objective. The stochasticity comes from sampling data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient_svm(A_sample, b_sample, lambda_, w_t, num_data_points):\n",
    "    \"\"\"\n",
    "    Calculate stochastic gradient over A_batch, b_batch.\n",
    "    A_sample: A data sample, shape=(num_features)\n",
    "    b_sample: Corresponding +1 or -1 label, scalar\n",
    "    w_t: Model weights, shape=(num_features)\n",
    "    num_data_points: Total size of the dataset, scalar integer\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    reg_grad = 2 * lambda_ * w_t\n",
    "    if b_sample * A_sample @ w_t >= 1:\n",
    "        loss_grad = np.zeros(len(w_t))\n",
    "    else:\n",
    "        loss_grad = -np.sum(b_sample * A_sample, axis=0)\n",
    "    \n",
    "    return loss_grad + reg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_svm_demo(A, b, gamma, batch_size=1, trace=False):\n",
    "    history = defaultdict(list) if trace else None\n",
    "    num_data_points, num_features = np.shape(A)\n",
    "    max_iter = 100000\n",
    "    lambda_ = 0.01\n",
    "    \n",
    "    w_t = np.zeros(num_features)\n",
    "    \n",
    "    current_iter = 0\n",
    "    while (current_iter < max_iter):\n",
    "        i = random.randint(0,num_data_points - 1)\n",
    "        b_batch, A_batch = b[i], A[i]\n",
    "        gradient = compute_stoch_gradient_svm(A_batch, b_batch, lambda_, w_t, num_data_points)\n",
    "        w_t = w_t - gamma * gradient\n",
    "        if current_iter % 1000 == 0:\n",
    "            primal_value = calculate_primal_objective(y, A, w_t, lambda_)\n",
    "            print('iteration=%i, primal:%.5f'%(\n",
    "                    current_iter, primal_value))\n",
    "        if current_iter % 1000 == 0:\n",
    "            primal_value = calculate_primal_objective(y, A, w_t, lambda_)\n",
    "            if trace:\n",
    "                history['objective_function'].append(primal_value)\n",
    "                history['iter'].append(current_iter)\n",
    "        current_iter += 1\n",
    "    print(\"training accuracy = {l}\".format(l=calculate_accuracy(y, A, w_t)))\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different stepsized and find the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=0, primal:2409.47502\n",
      "iteration=1000, primal:687.78718\n",
      "iteration=2000, primal:647.88887\n",
      "iteration=3000, primal:640.63783\n",
      "iteration=4000, primal:638.33083\n",
      "iteration=5000, primal:634.61217\n",
      "iteration=6000, primal:627.34359\n",
      "iteration=7000, primal:626.78773\n",
      "iteration=8000, primal:626.92595\n",
      "iteration=9000, primal:626.91452\n",
      "iteration=10000, primal:626.79755\n",
      "iteration=11000, primal:626.90621\n",
      "iteration=12000, primal:626.73647\n",
      "iteration=13000, primal:628.71634\n",
      "iteration=14000, primal:626.71954\n",
      "iteration=15000, primal:626.74906\n",
      "iteration=16000, primal:628.70986\n",
      "iteration=17000, primal:626.93010\n",
      "iteration=18000, primal:629.21386\n",
      "iteration=19000, primal:626.72112\n",
      "iteration=20000, primal:628.25431\n",
      "iteration=21000, primal:626.79404\n",
      "iteration=22000, primal:626.76429\n",
      "iteration=23000, primal:626.75798\n",
      "iteration=24000, primal:626.81990\n",
      "iteration=25000, primal:626.93463\n",
      "iteration=26000, primal:627.03084\n",
      "iteration=27000, primal:626.84323\n",
      "iteration=28000, primal:627.02520\n",
      "iteration=29000, primal:627.02923\n",
      "iteration=30000, primal:627.00366\n",
      "iteration=31000, primal:627.00304\n",
      "iteration=32000, primal:627.02891\n",
      "iteration=33000, primal:626.93460\n",
      "iteration=34000, primal:626.90463\n",
      "iteration=35000, primal:626.95560\n",
      "iteration=36000, primal:626.93011\n",
      "iteration=37000, primal:626.83329\n",
      "iteration=38000, primal:626.96838\n",
      "iteration=39000, primal:627.01610\n",
      "iteration=40000, primal:626.79294\n",
      "iteration=41000, primal:627.42276\n",
      "iteration=42000, primal:626.75246\n",
      "iteration=43000, primal:626.88135\n",
      "iteration=44000, primal:626.87940\n",
      "iteration=45000, primal:626.89762\n",
      "iteration=46000, primal:626.98914\n",
      "iteration=47000, primal:626.97445\n",
      "iteration=48000, primal:626.89910\n",
      "iteration=49000, primal:627.05471\n",
      "iteration=50000, primal:627.07278\n",
      "iteration=51000, primal:627.02202\n",
      "iteration=52000, primal:627.12293\n",
      "iteration=53000, primal:627.03450\n",
      "iteration=54000, primal:626.99317\n",
      "iteration=55000, primal:626.98954\n",
      "iteration=56000, primal:626.94372\n",
      "iteration=57000, primal:626.94018\n",
      "iteration=58000, primal:626.94904\n",
      "iteration=59000, primal:626.78509\n",
      "iteration=60000, primal:626.95133\n",
      "iteration=61000, primal:626.89930\n",
      "iteration=62000, primal:626.91916\n",
      "iteration=63000, primal:626.84869\n",
      "iteration=64000, primal:626.74888\n",
      "iteration=65000, primal:626.87924\n",
      "iteration=66000, primal:626.79959\n",
      "iteration=67000, primal:626.78838\n",
      "iteration=68000, primal:626.93908\n",
      "iteration=69000, primal:626.83742\n",
      "iteration=70000, primal:626.92274\n",
      "iteration=71000, primal:627.05957\n",
      "iteration=72000, primal:627.10106\n",
      "iteration=73000, primal:627.18783\n",
      "iteration=74000, primal:627.04755\n",
      "iteration=75000, primal:626.93771\n",
      "iteration=76000, primal:627.09479\n",
      "iteration=77000, primal:627.31826\n",
      "iteration=78000, primal:627.16469\n",
      "iteration=79000, primal:627.15591\n",
      "iteration=80000, primal:627.11576\n",
      "iteration=81000, primal:627.20412\n",
      "iteration=82000, primal:627.06369\n",
      "iteration=83000, primal:626.91469\n",
      "iteration=84000, primal:626.70465\n",
      "iteration=85000, primal:626.83035\n",
      "iteration=86000, primal:626.69518\n",
      "iteration=87000, primal:626.69830\n",
      "iteration=88000, primal:626.68942\n",
      "iteration=89000, primal:626.68892\n",
      "iteration=90000, primal:626.78815\n",
      "iteration=91000, primal:626.97318\n",
      "iteration=92000, primal:627.03656\n",
      "iteration=93000, primal:627.08585\n",
      "iteration=94000, primal:627.08657\n",
      "iteration=95000, primal:626.87836\n",
      "iteration=96000, primal:626.83929\n",
      "iteration=97000, primal:626.75831\n",
      "iteration=98000, primal:627.80034\n",
      "iteration=99000, primal:626.74273\n",
      "training accuracy = 0.8922083165119096\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.0001\n",
    "history_sgd = stochastic_gradient_descent_svm_demo(A, y, gamma, trace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CD vs SGD')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(np.arange(len(history_cd['objective_function']))*1000, history_cd['objective_function'], label=\"CD\")\n",
    "plt.plot(np.arange(len(history_sgd['objective_function']))*1000, history_sgd['objective_function'], label=\"SGD\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Primal problem value\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"CD vs SGD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare SGD with Coordinate Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two algorithms in terms of convergence, time complexities per iteration. Which one is easier to use?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
